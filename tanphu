import asyncio
import json
import uuid
import httpx
import os
import time
from aiohttp import web
from collections import deque, defaultdict
from datetime import datetime

# =================== CONFIG ===================
PLACE_ID = 109983668079237
HOST = "0.0.0.0"
PORT = 8080

SCAN_INTERVAL = 60
MAX_SERVERS = 200
REFILL_BATCH = 200

ROBLOX_API = "https://games.roblox.com/v1/games/{}/servers/Public?sortOrder=Asc&limit=100"

# üîê PROXY CONFIG (ch·ªâ d√πng cho scan API, kh√¥ng b·∫Øt Roblox client ƒëi qua)
PROXY_HOST = "103.166.184.192"
PROXY_PORT = "26235"
PROXY_USER = "user26235"
PROXY_PASS = "1758360642"
PROXY_URL = f"http://{PROXY_USER}:{PROXY_PASS}@{PROXY_HOST}:{PROXY_PORT}"

# ====== LEASE POLICY ======
LEASE_TTL = 60            # gi√¢y: h·∫øt h·∫°n gi·ªØ ch·ªó n·∫øu client treo
RESCAN_COOLDOWN = 3       # gi√¢y: cho ph√©p qu√©t b√π n·∫øu /next g·ªçi l√∫c h·∫øt h√†ng
# ==========================

# =================== STATE ===================
job_queue = deque()                      # ch·ªâ fresh jobs
assigned_jobs = set()                    # ƒëang ƒë∆∞·ª£c gi·ªØ b·ªüi client
leases = {}                              # jid -> expire_ts

client_stats = defaultdict(int)
queue_lock = asyncio.Lock()

last_scan_time = 0
next_scan_time = 0
scan_counter = 0

skip_count = 0


# =================== CLEAR ===================
def clear_console():
    os.system("cls" if os.name == "nt" else "clear")


# =================== FETCH SERVERS (multi-page) ===================
# L·∫§Y T·∫§T C·∫¢ SERVER >=1 PLAYER, ∆ØU TI√äN SERVER ƒê√îNG NG∆Ø·ªúI (TOP 5 LOG RA)
async def fetch_servers(max_count=MAX_SERVERS):
    servers = []
    cursor = None
    fetched = 0
    headers = {"User-Agent": "CTHub-Scanner/1.0"}

    async with httpx.AsyncClient(
        timeout=10.0,
        verify=False,
        proxy=PROXY_URL,
        headers=headers
    ) as client:
        while len(servers) < max_count:
            url = ROBLOX_API.format(PLACE_ID)
            if cursor:
                url += f"&cursor={cursor}"

            try:
                res = await client.get(url)
                data = res.json()
            except Exception as e:
                print(f"‚ö†Ô∏è fetch_servers l·ªói: {e}")
                break

            for s in data.get("data", []):
                fetched += 1
                if fetched <= skip_count:
                    continue

                jid = str(s.get("id", ""))
                if not jid:
                    continue

                playing = int(s.get("playing", 0) or 0)

                # b·ªè server 0 player
                if playing <= 0:
                    continue

                servers.append({"id": jid, "playing": playing})

                if len(servers) >= max_count:
                    break

            if len(servers) >= max_count:
                break

            cursor = data.get("nextPageCursor")
            if not cursor:
                break

    if not servers:
        print("‚ö†Ô∏è fetch_servers: KH√îNG c√≥ server n√†o (>=1 player).")
        return []

    # sort nhi·ªÅu ng∆∞·ªùi ‚Üí √≠t ng∆∞·ªùi
    servers.sort(key=lambda s: s["playing"], reverse=True)

    top5 = servers[:5]
    print(
        f"‚úÖ fetch_servers: l·∫•y {len(servers)} server (>=1 player). "
        f"Top 5 server ƒê√îNG ng∆∞·ªùi: {[s['playing'] for s in top5]}"
    )

    return servers


# =================== SWEEPER (ch·ªâ clear lease, KH√îNG requeue) ===================
async def sweep_expired_leases():
    now = time.time()
    expired = [jid for jid, exp in list(leases.items()) if exp <= now]
    if not expired:
        return

    async with queue_lock:
        for jid in expired:
            leases.pop(jid, None)
            assigned_jobs.discard(jid)

    if expired:
        print(f"‚ôªÔ∏è Clear {len(expired)} job h·∫øt h·∫°n lease (KH√îNG t√°i s·ª≠ d·ª•ng).")


# =================== UPDATE QUEUE ‚Äî SCAN ===================
async def update_queue():
    global last_scan_time, next_scan_time, scan_counter

    scan_counter += 1
    new_servers = await fetch_servers(MAX_SERVERS)

    async with queue_lock:
        # üî• XO√Å TO√ÄN B·ªò FRESH C≈®, KH√îNG C·ªòNG D·ªíN
        old_count = len(job_queue)
        job_queue.clear()

        count_new = 0
        # ch·ªâ th√™m job M·ªöI kh√¥ng tr√πng v·ªõi assigned hi·ªán t·∫°i
        for s in reversed(new_servers):  # new_servers ƒë√£ sort nhi·ªÅu‚Üí√≠t
            jid = s["id"]
            if jid in assigned_jobs:
                continue
            job_queue.appendleft(jid)
            count_new += 1

        last_scan_time = time.time()
        next_scan_time = last_scan_time + SCAN_INTERVAL

    now = datetime.now().strftime("%H:%M:%S")
    print((
        "üîÑ Scan #{0} | Xo√° {3} job c≈©, Th√™m {1} server m·ªõi l√∫c {2}"
        if count_new > 0 else
        "‚ö†Ô∏è Scan #{0} | Xo√° {3} job c≈©, Kh√¥ng c√≥ server m·ªõi l√∫c {2}"
    ).format(scan_counter, count_new, now, old_count))
    print(f"üì¶ Fresh: {len(job_queue)}\n")


# =================== TIMER ===================
async def timer_loop():
    while True:
        remaining = max(0, int(next_scan_time - time.time()))
        print(f"üïí C√≤n {remaining}s tr∆∞·ªõc khi qu√©t...", end="\r")
        await sweep_expired_leases()
        await asyncio.sleep(1)


# =================== SCANNER LOOP ===================
async def scanner_loop():
    while True:
        await update_queue()
        await asyncio.sleep(SCAN_INTERVAL)


# =================== HANDLE NEXT ===================
async def handle_next(request):
    client = request.remote or "unknown"
    client_stats[client] += 1

    # L·∫ßn 1: l·∫•y t·ª´ queue hi·ªán t·∫°i
    async with queue_lock:
        jid = None
        source = "fresh"

        if job_queue:
            jid = job_queue.popleft()

        if jid:
            assigned_jobs.add(jid)
            leases[jid] = time.time() + LEASE_TTL
            print(f"{client} ‚Üí {jid} | {source} | fresh={len(job_queue)}")
            try:
                return web.json_response(
                    {"jobId": jid, "placeId": PLACE_ID, "nonce": str(uuid.uuid4())}
                )
            except (ConnectionResetError, asyncio.CancelledError, BrokenPipeError):
                # client disconnect: CH·ªà clear, KH√îNG requeue job
                leases.pop(jid, None)
                assigned_jobs.discard(jid)
                print(f"‚ö†Ô∏è {client} disconnect ‚Üí drop {jid}")
                raise

    # H·∫øt h√†ng ‚Üí th·ª≠ quick-rescan
    await sweep_expired_leases()
    if time.time() - last_scan_time >= RESCAN_COOLDOWN:
        try:
            await update_queue()
        except Exception as e:
            print(f"‚ö†Ô∏è quick-rescan error: {e}")

    # L·∫ßn 2: th·ª≠ l·∫•y l·∫°i sau quick-rescan
    async with queue_lock:
        jid = None
        source = "fresh"

        if job_queue:
            jid = job_queue.popleft()
        else:
            return web.json_response({
                "jobId": None,
                "message": "H·∫øt job, ƒë·ª£i l·∫ßn qu√©t 60s ti·∫øp theo."
            })

        assigned_jobs.add(jid)
        leases[jid] = time.time() + LEASE_TTL
        print(f"{client} ‚Üí {jid} | {source} (after refill) | fresh={len(job_queue)}")
        return web.json_response(
            {"jobId": jid, "placeId": PLACE_ID, "nonce": str(uuid.uuid4())}
        )


# =================== ACK ===================
async def handle_ack(request):
    jid = request.query.get("jobId")
    if not jid:
        return web.json_response({"ok": False, "error": "missing jobId"}, status=400)

    async with queue_lock:
        leases.pop(jid, None)
        assigned_jobs.discard(jid)
    # KH√îNG requeue job n·ªØa
    return web.json_response({"ok": True})


# =================== STATUS ===================
async def handle_status(request):
    remaining = max(0, int(next_scan_time - time.time()))
    return web.json_response({
        "placeId": PLACE_ID,
        "fresh_queue": len(job_queue),
        "assigned": len(assigned_jobs),
        "leases": len(leases),
        "scan_count": scan_counter,
        "next_refresh_in_sec": remaining,
        "proxy": f"{PROXY_HOST}:{PROXY_PORT}"
    })


# =================== MAIN ===================
async def main():
    global skip_count
    clear_console()
    try:
        skip_count = int(input("B·ªè bao nhi√™u server ƒë·∫ßu ti√™n (0 n·∫øu kh√¥ng): ") or 0)
    except Exception:
        skip_count = 0

    print("üöÄ Kh·ªüi ƒë·ªông server...")

    asyncio.create_task(scanner_loop())
    asyncio.create_task(timer_loop())

    app = web.Application()
    app.router.add_get("/next", handle_next)
    app.router.add_get("/status", handle_status)
    app.router.add_get("/ack", handle_ack)

    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, HOST, PORT)
    await site.start()

    print("‚úîÔ∏è Server ƒëang ch·∫°y...")
    await asyncio.Event().wait()


if __name__ == "__main__":
    asyncio.run(main())
