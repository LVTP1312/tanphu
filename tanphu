import asyncio
import json
import uuid
import httpx
import os
import time
from aiohttp import web
from collections import deque, defaultdict
from datetime import datetime

# =================== CONFIG ===================
PLACE_ID = 109983668079237
HOST = "0.0.0.0"
PORT = 8080

SCAN_INTERVAL = 60
MAX_SERVERS = 200
REFILL_BATCH = 200

ROBLOX_API = "https://games.roblox.com/v1/games/{}/servers/Public?sortOrder=Asc&limit=100"

# üîê PROXY CONFIG (ch·ªâ d√πng cho scan API, kh√¥ng b·∫Øt Roblox client ƒëi qua)
PROXY_HOST = "103.166.184.192"
PROXY_PORT = "26235"
PROXY_USER = "user26235"
PROXY_PASS = "1758360642"
PROXY_URL = f"http://{PROXY_USER}:{PROXY_PASS}@{PROXY_HOST}:{PROXY_PORT}"

# ====== LEASE/RESERVE POLICY ======
LEASE_TTL = 60            # gi√¢y: h·∫øt h·∫°n gi·ªØ ch·ªó n·∫øu client treo
DISPATCH_RATIO = 2        # 2 job fresh : 1 job reserve
RESCAN_COOLDOWN = 3       # gi√¢y: cho ph√©p qu√©t b√π n·∫øu /next g·ªçi l√∫c h·∫øt h√†ng
# ==================================

# =================== STATE ===================
job_queue = deque()                      # fresh jobs (∆∞u ti√™n)
recent_jobs = deque(maxlen=5000)         # reserve kho d·ª± ph√≤ng
assigned_jobs = set()                    # ƒëang ƒë∆∞·ª£c gi·ªØ b·ªüi client
leases = {}                              # jid -> expire_ts

client_stats = defaultdict(int)
queue_lock = asyncio.Lock()

last_scan_time = 0
next_scan_time = 0
scan_counter = 0
dispatch_counter = 0

skip_count = 0
# last_public_ids = set()   # KH√îNG c√≤n d√πng ƒë·ªÉ xo√° PRIVATE n·ªØa


# =================== CLEAR ===================
def clear_console():
    os.system("cls" if os.name == "nt" else "clear")


# =================== FETCH SERVERS (multi-page) ===================
# ∆ØU TI√äN server 2‚Äì8 player, nh∆∞ng n·∫øu KH√îNG C√ì th√¨ fallback sang server kh√°c (>=1 player, kh√¥ng full)
async def fetch_servers(max_count=MAX_SERVERS):
    preferred = []  # 2‚Äì8 player
    others = []     # c√≤n l·∫°i (>=1, kh√¥ng full)
    cursor = None
    fetched = 0
    headers = {"User-Agent": "CTHub-Scanner/1.0"}

    async with httpx.AsyncClient(
        timeout=10.0,
        verify=False,
        proxy=PROXY_URL,
        headers=headers
    ) as client:
        while len(preferred) < max_count and len(others) < max_count:
            url = ROBLOX_API.format(PLACE_ID)
            if cursor:
                url += f"&cursor={cursor}"

            try:
                res = await client.get(url)
                data = res.json()
            except Exception as e:
                print(f"‚ö†Ô∏è fetch_servers l·ªói: {e}")
                break

            for s in data.get("data", []):
                fetched += 1
                if fetched <= skip_count:
                    continue

                jid = str(s.get("id", ""))
                if not jid:
                    continue

                playing = int(s.get("playing", 0) or 0)
                max_players = int(s.get("maxPlayers", 0) or 0)

                # b·ªè server 0 player
                if playing <= 0:
                    continue

                # b·ªè server full
                if max_players and playing >= max_players:
                    continue

                entry = {"id": jid, "playing": playing}

                if 2 <= playing <= 8:
                    preferred.append(entry)
                else:
                    others.append(entry)

                # d·ª´ng khi ƒë·ªß max_count ·ªü 1 trong 2 list
                if len(preferred) >= max_count or len(others) >= max_count:
                    break

            cursor = data.get("nextPageCursor")
            if not cursor:
                break

    # ch·ªçn list n√†o ƒë·ªÉ d√πng
    if preferred:
        servers = preferred
        print(
            f"‚úÖ fetch_servers: ∆ØU TI√äN {len(servers)} server 2‚Äì8 player "
            f"(min={min(s['playing'] for s in servers)}, max={max(s['playing'] for s in servers)})"
        )
    else:
        servers = others
        if servers:
            print(
                f"‚ö†Ô∏è fetch_servers: KH√îNG c√≥ server 2‚Äì8 player, d√πng {len(servers)} server kh√°c "
                f"(min={min(s['playing'] for s in servers)}, max={max(s['playing'] for s in servers)})"
            )
        else:
            print("‚ö†Ô∏è fetch_servers: KH√îNG c√≥ server ph√π h·ª£p n√†o (>=1 player, kh√¥ng full).")

    # sort √≠t ng∆∞·ªùi ‚Üí nhi·ªÅu ng∆∞·ªùi
    servers.sort(key=lambda s: s["playing"])
    return servers


# =================== SWEEPER (requeue lease h·∫øt h·∫°n) ===================
async def sweep_expired_leases():
    now = time.time()
    expired = [jid for jid, exp in list(leases.items()) if exp <= now]
    if not expired:
        return

    async with queue_lock:
        requeued = 0
        for jid in expired:
            leases.pop(jid, None)
            assigned_jobs.discard(jid)
            if jid not in job_queue and jid not in recent_jobs:
                job_queue.appendleft(jid)
                requeued += 1

    if requeued:
        print(f"‚ôªÔ∏è Requeue {requeued} job h·∫øt h·∫°n lease ‚Üí fresh={len(job_queue)}")


# =================== UPDATE QUEUE ‚Äî SCAN ===================
async def update_queue():
    global last_scan_time, next_scan_time, scan_counter

    scan_counter += 1
    new_servers = await fetch_servers(MAX_SERVERS)

    count_new = 0
    async with queue_lock:
        # ƒê∆∞a job m·ªõi l√™n ƒë·∫ßu, b·ªè tr√πng
        for s in reversed(new_servers):  # new_servers ƒë√£ sort √≠t‚Üínhi·ªÅu
            jid = s["id"]
            if jid in assigned_jobs or jid in recent_jobs or jid in job_queue:
                continue
            job_queue.appendleft(jid)
            count_new += 1

        last_scan_time = time.time()
        next_scan_time = last_scan_time + SCAN_INTERVAL

    now = datetime.now().strftime("%H:%M:%S")
    print((
        "üîÑ Scan #{0} | Th√™m {1} server m·ªõi l√∫c {2}"
        if count_new > 0 else
        "‚ö†Ô∏è Scan #{0} | Kh√¥ng c√≥ server m·ªõi l√∫c {2}"
    ).format(scan_counter, count_new, now))
    print(f"üì¶ Fresh: {len(job_queue)} | Reserve: {len(recent_jobs)}\n")


# =================== TIMER ===================
async def timer_loop():
    while True:
        remaining = max(0, int(next_scan_time - time.time()))
        print(f"üïí C√≤n {remaining}s tr∆∞·ªõc khi qu√©t...", end="\r")
        await sweep_expired_leases()
        await asyncio.sleep(1)


# =================== SCANNER LOOP ===================
async def scanner_loop():
    while True:
        await update_queue()
        await asyncio.sleep(SCAN_INTERVAL)


# =================== HANDLE NEXT ===================
async def handle_next(request):
    client = request.remote or "unknown"
    client_stats[client] += 1

    async with queue_lock:
        global dispatch_counter
        dispatch_counter += 1
        pick_from_reserve = (dispatch_counter % (DISPATCH_RATIO + 1) == 0)

        jid = None
        source = None

        if pick_from_reserve and recent_jobs:
            jid = recent_jobs.popleft()
            source = "FALLBACK"
        elif job_queue:
            jid = job_queue.popleft()
            recent_jobs.append(jid)
            source = "fresh"
        elif recent_jobs:
            jid = recent_jobs.popleft()
            source = "FALLBACK"

        if jid:
            assigned_jobs.add(jid)
            leases[jid] = time.time() + LEASE_TTL
            print(f"{client} ‚Üí {jid} | {source} | fresh={len(job_queue)} reserve={len(recent_jobs)}")
            try:
                return web.json_response({"jobId": jid, "placeId": PLACE_ID, "nonce": str(uuid.uuid4())})
            except (ConnectionResetError, asyncio.CancelledError, BrokenPipeError):
                leases.pop(jid, None)
                assigned_jobs.discard(jid)
                if source == "fresh":
                    job_queue.appendleft(jid)
                else:
                    recent_jobs.appendleft(jid)
                print(f"‚ö†Ô∏è {client} disconnect ‚Üí requeue {jid}")
                raise

    await sweep_expired_leases()
    if time.time() - last_scan_time >= RESCAN_COOLDOWN:
        try:
            await update_queue()
        except Exception as e:
            print(f"‚ö†Ô∏è quick-rescan error: {e}")

    async with queue_lock:
        jid = None
        source = None

        if job_queue:
            jid = job_queue.popleft()
            recent_jobs.append(jid)
            source = "fresh"
        elif recent_jobs:
            jid = recent_jobs.popleft()
            source = "FALLBACK"
        else:
            return web.json_response({
                "jobId": None,
                "message": "H·∫øt job, ƒë·ª£i l·∫ßn qu√©t 60s ti·∫øp theo."
            })

        assigned_jobs.add(jid)
        leases[jid] = time.time() + LEASE_TTL
        print(f"{client} ‚Üí {jid} | {source} (after refill) | fresh={len(job_queue)} reserve={len(recent_jobs)}")
        return web.json_response({"jobId": jid, "placeId": PLACE_ID, "nonce": str(uuid.uuid4())})


# =================== ACK ===================
async def handle_ack(request):
    jid = request.query.get("jobId")
    if not jid:
        return web.json_response({"ok": False, "error": "missing jobId"}, status=400)

    async with queue_lock:
        leases.pop(jid, None)
        assigned_jobs.discard(jid)
    return web.json_response({"ok": True})


# =================== STATUS ===================
async def handle_status(request):
    remaining = max(0, int(next_scan_time - time.time()))
    return web.json_response({
        "placeId": PLACE_ID,
        "fresh_queue": len(job_queue),
        "fallback_store": len(recent_jobs),
        "assigned": len(assigned_jobs),
        "leases": len(leases),
        "scan_count": scan_counter,
        "next_refresh_in_sec": remaining,
        "proxy": f"{PROXY_HOST}:{PROXY_PORT}"
    })


# =================== MAIN ===================
async def main():
    global skip_count
    clear_console()
    try:
        skip_count = int(input("B·ªè bao nhi√™u server ƒë·∫ßu ti√™n (0 n·∫øu kh√¥ng): ") or 0)
    except Exception:
        skip_count = 0

    print("üöÄ Kh·ªüi ƒë·ªông server...")

    asyncio.create_task(scanner_loop())
    asyncio.create_task(timer_loop())

    app = web.Application()
    app.router.add_get("/next", handle_next)
    app.router.add_get("/status", handle_status)
    app.router.add_get("/ack", handle_ack)

    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, HOST, PORT)
    await site.start()

    print("‚úîÔ∏è Server ƒëang ch·∫°y...")
    await asyncio.Event().wait()


if __name__ == "__main__":
    asyncio.run(main())
